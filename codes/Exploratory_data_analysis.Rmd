---
title: "Exploratory_data_analysis"
author: "Charles Anchang"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: monochrome
    toc: yes
    toc_float: no
    toc_depth: 6
    code_folding: hide
  github_document:
    theme: cosmo
    highlight: monochrome
    toc: yes
    toc_float: no
    toc_depth: 6
    code_folding: hide
  word_document:
    toc: yes
    toc_depth: '6'
  pdf_document:
    toc: yes
    toc_depth: '6'
editor_options:
  chunk_output_type: console
---

```{css, echo=FALSE}
<style>
body, h1, h2, h3, h4 {
    font-family: "Bookman", serif;
}

body {
    color: #333333;
}
a, a:hover {
    color: red;
}
pre {
    font-size: 10px;
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## **Introduction**

RNA sequencing is a technique whereby RNA transcripts are converted to complementary DNA (cDNA) which is then sequenced to generate reads and the reads and mapped to a reference genome to generate counts which can be analysed statistically. But the statistical approaches differ than those used for microarrays because the RNA seq data consists of countsÂ´and not intensities. Counts are modeled using the Poisson or negative binomial distribution. These techniques are implemented in the **EdgeR** and **DESeq2** packages which are some of the most widely used RNA seq data analysis. Major complications with RNA seq data analysis are the need to account for the effects of splicing and to account for isoformy. In this analysis, I will not touch details on this topic. However So, while we have approaches like edgeR, DESeq, and **DEXSeq** that basically count each gene or each exon and quantifies the amount. We also have techniques that try to determine from the reads what transcripts are present. Some of these actually try to do it from scratch, without a reference genome.
Examples of these methods are **Trinity Oases**, **Cufflinks**, and **Scripture**.

I will however look at basic statistical approaches commonly used in RNA seq analysis.

## **Load libraries**

```{r}
library(dplyr) # wrangling
```


## **Transcriptome alignment assessment**

At a previous step not detailed in this analysis, transcript- and gene-level expression was calculated by probabilistic alignment using the RSEM software. The two result are saved in the **raw_data** folder.

```{r}
list.files("raw_data")
genes <- read.table("raw_data/SRR1039508.genes.results",
                    header = TRUE, stringsAsFactors = TRUE)

head(genes) %>%
  knitr::kable()
isoforms <- read.table("raw_data/SRR1039508.isoforms.results",
                       header = TRUE, stringsAsFactors = TRUE)
head(isoforms) %>%
  knitr::kable()
```

Both genes and isoforms have a column names the **FPKM(fragments per kilobase of sequence per million mapped reads) **.

I will confirm with the *split()* and *sapply()* functions that the FPKM column in genes is the sum of the FPKM colum in isoforms.

```{r}
fpkm.per.gene <- split(isoforms$FPKM, isoforms$gene_id)
head(sapply(fpkm.per.gene, sum))
head(genes$FPKM)
```

Alternatively

```{r}
isoforms %>% group_by(gene_id) %>% summarize(sum = sum(FPKM)) 
```

I will obtain FPKM values from the genes values and log transform it and make a histogram. But before that, I will start by removing all genes with FPKM values of 0. The log transformation will be $\log10(x + 1)$.

```{r}
genes2 <- genes[genes$FPKM > 0, ]
genes2$gene_id <- droplevels(genes2$gene_id)
isoforms2 <- isoforms[isoforms$gene_id %in% genes2$gene_id, ]
isoforms2$gene_id <- droplevels(isoforms2$gene_id)
```

To verify that the gene_id column in genes2 is equal to the levels of the gene_id column in isoforms2.

```{r}
stopifnot(all(genes2$gene_id == levels(isoforms2$gene_id)))
```

Plot of effective length vs expected count:

```{r}
head(genes2)
plot(log(genes2$effective_length),
     log(genes2$expected_count))
```

**Make a histogram of the FPKM in genes2**

```{r fig.align='center'}
genes2_fpkm <- log10(genes2$FPKM)
genes2_fpkm_pos <- genes2_fpkm[genes2_fpkm > 0]
median(genes2$FPKM)
hist(log10(genes2$FPKM))
```

**With isoforms2 , calculate the maximum IsoPct for each gene**

```{r}
head(isoforms2)

max.iso <- isoforms2 %>%
              group_by(gene_id) %>%
              summarize(max_isopc = max(IsoPct))
hist(max.iso$max_isopc)
mean(max.iso$max_isopc > 95)
```

**Is there a relationship between total expression and the maximum IsoPct for each gene?**

```{r fig.align='center'}
plot(max.iso$max_isopc,
     log(max.iso$max_isopc))
boxplot(split(log10(genes2$FPKM), 
              cut(max.iso$max_isopc, 5)), xlab="max.iso", ylab="log10 FPKM")
```

**Calculate the number of isoforms per gene, and plot the maximum IsoPct against the number of isoforms:**

```{r fig.align='center'}
num.iso <- as.numeric(table(isoforms2$gene_id))
plot(num.iso, max.iso$max_isopc)

barplot(table(num.iso))
barplot(table(num.iso[num.iso < 15]))
```

**TPM (transcripts per million)**, is a linear scaling of the FPKM, such that we would expect a gene with 1 TPM to have one molecule in a population of one million mRNAs.

With genes2, plot the TPM over the FPKM.

Confirm that TPM is equal to: (FPKM / sum(FPKM)) * 1e6

## **Normalization and EDA of gene counts**

In this section, I will be examining the gene level expression from a study which studies the RNA-seq transcription profiling in airway smooth muscle tissue.

The treatment of interest in this study was **dexamethasone** that binds to the glucocorticoid receptor and in general provides an anti-inflammatory response. When used in asthma, it helps to suppress autoimmune reactions which have undesirable symptoms. We have eight samples, four treated and four untreated. The files needed for the analysis are found in the bioconductor package called **airway**.

### Count the number of reads which uniquely align to exns of different genes.

Load the data, contained in **bam** and **gtf** files. GTF files has information about genes in the subset of chromosomes on interest. Please note that the bam and gtf files analysed here are not full but a subset.

```{r}
# BiocManager::install("airway")
library(airway)
library(tidyverse)

dir <- system.file("extdata", package = "airway", mustWork = TRUE)
csv.file <- file.path(dir, "sample_table.csv") # contains th counts table for all genes and samples
sample.table <- read.csv(csv.file, row.names = 1)
bam.files <- file.path(dir, paste0(sample.table$Run, "_subset.bam")) # subset bam files
gtf.file <- file.path(dir, "Homo_sapiens.GRCh37.75_subset.gtf")
```

Look at the counts matrix

```{r}
sample.table %>%
  head %>%
  knitr::kable()
```

### Building a counts matrix

```{r}
# BiocManager::install("Rsamtools")
library(Rsamtools)
bam.list <- BamFileList(bam.files) # yieldsize specifies how many reads to be read in at a time by any function that will use the bam files. Best to read all at once, why I do not specify it.
# BiocManager::install("GenomicFeatures")
library(GenomicFeatures) # helps to build a transcript database which contains all info about different genes, transcripts and exons
txdb <- makeTxDbFromGFF(gtf.file, format = "gtf") # txdb is a transcript database (db)
exons.by.gene <- exonsBy(txdb, by = "gene") # extract a GRanges list in which each element specifies a gene and within that element, we have exons for that gene. 
```

Txdb objects are SQLite databases and can be saved with **saveDb** and can be loaded with **loadDb**. 

Exploring the GRAnges object (exons.by.gene)

```{r}
exons.by.gene[[1]] %>%
  head %>%
  knitr::kable()
```

If we look at the first element in exons.by.gene object as in the table above, we get the exons for the first gene and the corresponding chromosome to which it is annotated.

```{r}
length(exons.by.gene)
```

The length of exons.by.gene gives us the number of genes in our subset.

```{r}
summary(elementNROWS(exons.by.gene))
```

The function *elementNROWS()* gives us the number of exons for every gene. We can see that some genes have only one exon, the another 70 and the mean number of exons is 12 in this subset.

```{r}
library(GenomicAlignments)
se <- summarizeOverlaps(exons.by.gene,
                        bam.list,
                        mode = "Union",
                        singleEnd = FALSE, # we want to count paired end reads
                        ignore.strand = TRUE, # we have unstranded rna seq data
                        fragments = TRUE) # used when we have paired end data
colData(se) <- DataFrame(sample.table)
```

So the actual count table is stored in a SummarizedExperiment in the assay slot.

```{r}
colData(se)
rowRanges(se)
```

```{r}
dim(assay(se))
```

```{r}
colSums(assay(se))
```


```{r}
# BiocManager::install("Rsubread")
library(Rsubread)

# function below is an alternate function to count read in genes
fc <- featureCounts(bam.files,
                    annot.ext = gtf.file,
                    isGTFAnnotationFile = TRUE,
                    isPairedEnd = TRUE)
names(fc)
fc$counts %>%
  head %>%
  knitr::kable()
```

below I compare the first sample counts for the summarizeOverlaps call and for the counts.
```{r fig.align='center'}
plot(assay(se)[, 1], fc$counts[match(rownames(se),
                                      rownames(fc$counts)), 1]);
abline(0, 1)
```

From the graph above we see that the counts fall in the y = x line, indicatint that both methods yield similar results.

## **Normalizing for sequencing depth**

### By taking the log2

```{r fig.align='center'}
library(airway)
data(airway)
airway
```

```{r}
colData(airway)
```

The table above contains metadata.

```{r}
rowRanges(airway)
```

The above this is GRangesList, where each element is a gene and it contains the exons of that gene.

```{r}
head(assay(airway))
```

The table above contains the counts of the various genes for each sample. The counts are the number of paired-end reads which align to each gene.

However, to be accurate about the number of reads which align to each gene, there are a number of issues to account for. One of them is the sequencing depth. The sequencing depth is the number of reads which aligned to genes.

```{r}
colSums(assay(airway))
```

The results from the command above gives the number of paired end reads which align the genes of each sample and we can sort that by  million.

```{r}
sort(colSums(assay(airway)))/ 1e6
```

We see the range is from 15 million to 30 million and this is a technical artifact we want to account for. If we also just look at the raw counts, we realise that the variance is much higher for large counts than for small counts, so if we compare the raw counts vector, the genes that have a very high count would be more important, and they would be adding more information to the distance than the small count genes.

```{r fig.align='center'}
plot(assay(airway)[, 1:2], cex = 0.1)
```

So we're going to first try out taking the log and dividing by a robust estimate of the sequencing depth,
in order to make a distance comparison between samples. In order to have a robust estimate of the differences in sequencing depth, we're going to use the DESeq2 package.

```{r}
# BiocManager::install("DESeq2")
library(DESeq2)

dds <- DESeqDataSet(airway, design =  ~ cell + dex) # you can also put ~ 1 if you do not know what to ut, just to estimate the size factors.
```

We can also make a *DESeqDataSet* from count matrix and column data.

The following estimates size factors to account for differences in sequencing depth, and is only necessary to have the `logcounts` object below.

```{r}
library(rafalib)

dds <- estimateSizeFactors(dds) # gives robust estimate in differences in sequencing depth.
sizeFactors(dds)
colSums(counts(dds))
plot(sizeFactors(dds), colSums(counts(dds)))
abline(lm(colSums(counts(dds)) ~ sizeFactors(dds) + 0) )
```

So the size factors are generally around one. When they're lower, it indicates that a sample had lower sequencing depth.And when they're higher-- for here, 1.4-- it indicates that a sample had higher sequencing depth.  

So we can see that a fitted line which also goes through zero generally follows the column sums.
But the reason why the size factors are considered more robustis that if we had a single count with a very large value-- so if one of the genes had 10 million counts-- this would have a huge effect on the column sums, but it would have almost no effect on the size factors, because they're calculated using the median.

```{r}
loggeomeans <- rowMeans(log(counts(dds)))
hist(log(counts(dds)[, 1]) - loggeomeans,
     col = "grey", maint ="", xlab = "", breaks = 40)
```

We can take a matrix of the log counts normalised by sequencing depth:

```{r}
log.norm.count <- log2(counts(dds, normalized = TRUE) + 1)
```

To see what would happen if we had not normalised by sequencing depth:

```{r fig.align='center'}
rs <- rowSums(counts(dds))
mypar(1, 2)
boxplot(log2(counts(dds)[rs > 0, ] + 1)) # not normalised
boxplot(log.norm.count[rs > 0, ]) # normalised
```

You can see that from the top of the box, which is the 3/4 quartile,and from the median, for example, which is the thick line, in the left plot is jagged and on the right plot it's more flat. So normalizing for sequencing depth is an important first step. And we've also taken the log, and the log has brought the data onto a more comparable scale.

Plotting distances between two samples for the normalised data

```{r fig.align='center'}
mypar(1, 1)
plot(log.norm.count[, 1:2])
```

We see from the plot above that there is more stable variance between the two samples than in the previous related plot.So the variance between the two samples is more constant along the range. So whereas before, this trumpeted out towards the higher values, now the variance between the two samples is more flat.
Although at the bottom here, where the counts become very close to zero, there is a higher spread, and that's what we're going to examine in the next video.

### By stabilising the count variance

So in this section, we're going to discuss a more sophisticated transformation, which helps to stabilize the variance at different levels of the mean. We use the `rlog` from the DESeq2 package, which is suitable when the size factors vary widely. The result of using the rlog transformation is to shrink together the values for the genes that have very low counts, and that's where the term regularization comes in, which is typically, in statistics, a shrinkage. And for the genes that have medium to high counts, the rlog will be very close to the log2 transform. So we can immediately use the same plot to compare just the rlog
values for two samples.

```{r}
rld <- rlog(dds)
```

So we can immediately use the same plot to compare just the rlog values for two samples. So we can see now that at the low end-- so, for example, when the log2 is less than 1 in this area, the values for the two samples are shrunk together to the identity line.

```{r}
plot(assay(rld)[, 1], assay(rld)[, 2], cex = 0.1)
```

So another plot to examine the difference between these two transformations, the log2 and the rlog, is
in the `vsn` package, which contains a mean standard deviation plot. And the means standard deviation plot for each gene calculates the mean over all samples and the standard deviation over all samples.

```{r fig.align='center'}
# BiocManager::install("vsn")
library(vsn)
mypar(1, 2)
meanSdPlot(log.norm.count, ranks = FALSE, ylim = c(0, 3))
meanSdPlot(assay(rld), ranks = FALSE, ylim = c(0, 3))
```

And by comparing the two plots, you can see that the standard deviation spikes early for the log2 plus 1 matrix, and it slowly builds up from 0 for the rlog matrix. So for the rlog matrix, the genes that have a count larger than 5, so for a count larger than 32, those are the genes with the high standard deviation.
Whereas on the left, the genes that have a mean count of 1 are the genes that have the high standard deviation. So this stabilization of the variance is a useful property of the rlog.

**Principal components analysis**

One of the most important plots that we can make for exploratory data analysis is a principal component plot.

```{r fig.align='center'}
mypar()
rv <- apply(log.norm.count, 1, var)
topgenes <- head(order(rv, decreasing = TRUE), 500)
pc <- prcomp(t(log.norm.count[topgenes, ]))
plot(pc$x[, 1], pc$x[, 2],
     col = colData(dds)$dex,
     pch = as.integer(colData(dds)$cell))
```

Plotting pca on the rlog object

```{r}
plotPCA(rld, intgroup = "dex")
plotPCA(rld, intgroup = c("dex", "cell"))
```

PCA plot with `ggplot` library

```{r fig.align='center'}
library(ggplot2)
(data <- plotPCA(rld, intgroup = c("dex", "cell"), returnData = TRUE))
(percentVar <- 100 * round(attr(data, "percentVar"), 2))
makeLab <- function(x, pc) paste0("PC", pc, ": ", x, "% variance")
ggplot(data, aes(PC1, PC2, col = dex, shape = cell)) +
  geom_point() +
  xlab(makeLab(percentVar[1], 1)) +
  ylab(makeLab(percentVar[2], 2))
```

So now we can see we have the color separating treated and untreated,and the plotting symbol designates the cell type. So the principal component plot is a highly recommended exploratory plot.

And the last plot we're going to make in this exploratory section is a hierarchical clustering based on the Euclidean distance between the transformed count matrices.

```{r fig.align='center'}
mypar(2, 1)
plot(hclust(dist(t(log.norm.count))), labels = colData(dds)$dex)
plot(hclust(dist(t(assay(rld)))), labels = colData(rld)$dex)
```

## **Session information**

```{r}
sessionInfo()
```

